{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d0d1a6",
   "metadata": {},
   "source": [
    "<h1> unsupervised learning using Kmeans</h1>\n",
    "various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e94612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from numba import cuda\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from utilities import VGG16_features, path_discovery, pca_extraction, input_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62674b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model + higher level layers\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a482271",
   "metadata": {},
   "source": [
    "<h2>select feature extraction method</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf3b9e",
   "metadata": {},
   "source": [
    "function to visualize and extract features with vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99396176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "#features = VGG16_features('images_dataset/apple fruit/image_26.jpg', base_model, layer_name='block4_conv3',visualize=False)\n",
    "#print(\"Extracted Features Shape:\", features.shape)\n",
    "\n",
    "#Existing layers are: ['input_1', 'block1_conv1-2', 'block1_pool', 'block2_conv1-2', 'block2_pool',\n",
    "#'block3_conv1-2-3', 'block3_pool', 'block4_conv1-2-3', 'block4_pool', 'block5_conv1-2-3', 'block5_pool', 'flatten', 'fc1', 'fc2', 'fc2'].\n",
    "\n",
    "extracted_feature_list=[]\n",
    "\n",
    "res = path_discovery('images_dataset/')\n",
    "\n",
    "for i in res.img_paths:\n",
    "    features = VGG16_features(i, base_model, layer_name='fc2',visualize=False)\n",
    "    extracted_feature_list.append(features)\n",
    "\n",
    "\n",
    "extracted_feature_list = np.array(extracted_feature_list)\n",
    "eval_image_names = np.array(res.img_paths)\n",
    "dirs_visited = np.array(res.dirs_visited)\n",
    "print(\"features shape\",extracted_feature_list.shape)\n",
    "\n",
    "with open('features_labels.pkl', 'wb') as f:\n",
    "    pickle.dump((extracted_feature_list, eval_image_names, res.labels,dirs_visited), f)\n",
    "\n",
    " \n",
    "del res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59020afa",
   "metadata": {},
   "source": [
    "function to extract features with autoencoder (must be trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING the model that is loaded must be present in working directory, if not, it means it must be trained first\n",
    "#go to last code cell to train the autoencoder model\n",
    "\n",
    "encoder= tf.keras.models.load_model('autoencoder_model')\n",
    "\n",
    "encoder_model= Model(inputs=encoder.input, outputs=encoder.get_layer('bottleneck').output)\n",
    "\n",
    "paths=path_discovery('images_dataset')\n",
    "eval_image_names = np.array(paths.img_paths)\n",
    "dirs_visited = np.array(paths.dirs_visited)\n",
    "res=input_preprocessing(paths.img_paths)\n",
    "\n",
    "feature_vector= np.array(res.feature_vector)\n",
    "feature_vector=feature_vector/255\n",
    "\n",
    "\n",
    "extracted_feature_list=encoder_model.predict(feature_vector)\n",
    "print(\"features shape\",extracted_feature_list.shape)\n",
    "\n",
    "with open('features_labels.pkl', 'wb') as f:\n",
    "    pickle.dump((extracted_feature_list, eval_image_names, paths.labels,dirs_visited), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388911a",
   "metadata": {},
   "source": [
    "<h2>model Kmeans training, with PCA reduced features</h2>\n",
    "(labels are included for evaluation of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('features_labels.pkl', 'rb') as f:\n",
    "    extracted_feature_list, eval_image_names, labels, dirs_visited = pickle.load(f)\n",
    "print(\"array1 features\",extracted_feature_list.shape)\n",
    "\n",
    "#feature reduction 2D using tsne (for visualization only)\n",
    "tsne = TSNE(n_components=2)\n",
    "pca_object=pca_extraction(extracted_feature_list,0.8)\n",
    "tsne_result=tsne.fit_transform(pca_object.pca_result)\n",
    "\n",
    "#Kmeans clustering using PCA reduced features\n",
    "Kmeans= KMeans(n_clusters=9,init='k-means++')\n",
    "Kmeans.fit(pca_object.pca_result)\n",
    "Kmeans_labels=Kmeans.labels_\n",
    "\n",
    "#  Visualize the clustering results\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=Kmeans_labels, cmap='tab20c',s=9)\n",
    "plt.title('t-SNE Visualization of Clusters')\n",
    "\n",
    "#  Compare with true labels\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='tab20c',s=9)\n",
    "plt.title('t-SNE Visualization with True Labels')\n",
    "plt.show()\n",
    "\n",
    "#clustering result\n",
    "accuracy=adjusted_rand_score(Kmeans_labels,labels)\n",
    "\n",
    "#confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, Kmeans_labels)\n",
    "\n",
    "#creating a dictionary that maps the \"cluster labels\" number to the most likely correct \"true labels\" number\n",
    "row_ind, col_ind = linear_sum_assignment(-conf_matrix)\n",
    "label_mapping = dict(zip(col_ind, row_ind))\n",
    "mapped_Kmeans_labels = np.array([label_mapping[label] for label in Kmeans_labels])\n",
    "remapped_conf_matrix = confusion_matrix(labels, mapped_Kmeans_labels)\n",
    "\n",
    "#how often the positive predictions are correct?\n",
    "precision = precision_score(labels, mapped_Kmeans_labels, average='weighted')\n",
    "# can an ML model find all instances of the positive class?\n",
    "recall = recall_score(labels, mapped_Kmeans_labels, average='weighted')\n",
    "#how often the model is right? (if the class numbers are unbalanced between TP and TN, the accuracy will fail)\n",
    "accuracy = accuracy_score(labels, mapped_Kmeans_labels)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#retrieve class names from the path discovery at beginning\n",
    "dirs_basename= [os.path.basename(d) for d in dirs_visited]\n",
    "\n",
    "# Visualize the remapped confusion matrix using a heatmap\n",
    "sns.heatmap(remapped_conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dirs_basename[1:len(dirs_basename)],\n",
    "            yticklabels=dirs_basename[1:len(dirs_basename)])\n",
    "plt.xlabel('Cluster Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "missed_images=[]\n",
    "missed_indices= np.where(labels != mapped_Kmeans_labels)[0]\n",
    "missed_images = eval_image_names[missed_indices]\n",
    "\n",
    "print(\"Misclassified Images:\")\n",
    "for img in missed_images:\n",
    "    print(img)\n",
    "if 'features' in globals():\n",
    "    del features\n",
    "if 'extracted_feature_list' in globals():\n",
    "    del extracted_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad2d0b",
   "metadata": {},
   "source": [
    "<h2>model Kmeans evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b407126",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir2='eval_dataset/'\n",
    "eval_features=[]\n",
    "\n",
    "\n",
    "res= path_discovery(img_dir2)\n",
    "\n",
    "for i in res.img_paths:\n",
    "    features = VGG16_features(i, base_model, layer_name='fc2',visualize=False)\n",
    "    eval_features.append(features)\n",
    "\n",
    "\n",
    "eval_features = np.array(eval_features)\n",
    "eval_image_names = np.array(res.img_paths)\n",
    "eval_image_names= [os.path.basename(d) for d in eval_image_names]\n",
    "\n",
    "\n",
    "print('feature list shape', eval_features.shape)\n",
    "\n",
    "#apply transformation matrix of PCA, previously calculated, to reduce feature vector size\n",
    "eval_features=pca_object.pca.transform(eval_features)\n",
    "\n",
    "print('reduced feature list shape', eval_features.shape)\n",
    "\n",
    "pred_clusters=Kmeans.predict(eval_features)\n",
    "#print('predicted_SVM_labels cluster',pred_clusters)\n",
    "\n",
    "#using the mapping dictionary created in the training phase\n",
    "mapped_Kmeans_labels = np.array([label_mapping[label] for label in pred_clusters])\n",
    "#print('mapped predicted_SVM_labels cluster',mapped_Kmeans_labels)\n",
    "\n",
    "\n",
    "remapped_conf_matrix = confusion_matrix(res.labels, mapped_Kmeans_labels)\n",
    "\n",
    "#how often the positive predictions are correct?\n",
    "precision = precision_score(res.labels, mapped_Kmeans_labels, average='weighted')\n",
    "# can an ML model find all instances of the positive class?\n",
    "recall = recall_score(res.labels, mapped_Kmeans_labels, average='weighted')\n",
    "#ow often the model is right? (if the class numbers are unbalanced between TP and TN, the accuracy will fail)\n",
    "accuracy = accuracy_score(res.labels, mapped_Kmeans_labels)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#retrieve class names from the path discovery at beginning\n",
    "dirs_basename= [os.path.basename(d) for d in res.dirs_visited]\n",
    "\n",
    "# Visualize the remapped confusion matrix using a heatmap\n",
    "sns.heatmap(remapped_conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dirs_basename[1:len(dirs_basename)],\n",
    "            yticklabels=dirs_basename[1:len(dirs_basename)])\n",
    "plt.xlabel('Cluster Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for a in range(len(mapped_Kmeans_labels)):\n",
    "    print('real name:',eval_image_names[a], '   predicted_SVM_labels name:', dirs_basename[mapped_Kmeans_labels[a]])\n",
    "\n",
    "\n",
    "del res,features,eval_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb4e56",
   "metadata": {},
   "source": [
    "<h2>model SVM training</h2>\n",
    "(supervised method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2217ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with open('features_labels.pkl', 'rb') as f:\n",
    "    extracted_feature_list, eval_image_names, labels, dirs_visited= pickle.load(f)\n",
    "    \n",
    "#train 9 SVM one for each class\n",
    "kernel= 'linear'\n",
    "max_iterations=500\n",
    "\n",
    "models = [SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),\n",
    "          SVC(kernel=kernel, max_iter=max_iterations, probability=True),]\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    models[i].fit(extracted_feature_list, labels==i+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e998df2",
   "metadata": {},
   "source": [
    "model predictions on evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a21e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir2='eval_dataset/'\n",
    "eval_features=[]\n",
    "res= path_discovery(img_dir2)\n",
    "\n",
    "for i in res.img_paths:\n",
    "    features = VGG16_features(i, base_model, layer_name='fc2',visualize=False)\n",
    "    eval_features.append(features)\n",
    "\n",
    "\n",
    "eval_features = np.array(eval_features)\n",
    "eval_image_names = np.array(res.img_paths)\n",
    "eval_image_names= [os.path.basename(d) for d in eval_image_names]\n",
    "\n",
    "\n",
    "\n",
    "predict_score=[]\n",
    "for i in range(9):\n",
    "    #calculate probability of all samples for each model, then take only 2nd column\n",
    "    #which is the prob. that the sample BELONGS to that class (wherease [:,0] is the prob. to not belong)\n",
    "    predict_score.append(models[i].predict_proba(eval_features)[:,1])\n",
    "\n",
    "\n",
    "predict_score=np.asarray(predict_score)\n",
    "predicted_SVM_labels=np.argmax(predict_score,axis=0) +1 #because true labels start from 1\n",
    "\n",
    "conf_matrix1= confusion_matrix(res.labels,predicted_SVM_labels)\n",
    "\n",
    "#how often the positive predictions are correct?\n",
    "precision = precision_score(res.labels, predicted_SVM_labels, average='weighted')\n",
    "# can an ML model find all instances of the positive class?\n",
    "recall = recall_score(res.labels, predicted_SVM_labels, average='weighted')\n",
    "#ow often the model is right? (if the class numbers are unbalanced between TP and TN, the accuracy will fail)\n",
    "accuracy = accuracy_score(res.labels, predicted_SVM_labels)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "dirs_basename= [os.path.basename(d) for d in res.dirs_visited]\n",
    "sns.heatmap(conf_matrix1, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=dirs_basename[1:len(dirs_basename)],\n",
    "            yticklabels=dirs_basename[1:len(dirs_basename)])\n",
    "\n",
    "plt.xlabel('svm Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "for a in range(len(predicted_SVM_labels)):\n",
    "    print('real name:',eval_image_names[a], '   predicted name:', dirs_basename[predicted_SVM_labels[a]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99118cc",
   "metadata": {},
   "source": [
    "<h2>model DBscan training with PCA reduced features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4788bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features_labels.pkl', 'rb') as f:\n",
    "    extracted_feature_list, eval_image_names, labels, dirs_visited = pickle.load(f)\n",
    "\n",
    "print(\"array1 features\",extracted_feature_list.shape)\n",
    "\n",
    "#feature reduction 2D using tsne (for visualization only)\n",
    "tsne = TSNE(n_components=2)\n",
    "pca_object=pca_extraction(extracted_feature_list,0.7)\n",
    "tsne_result=tsne.fit_transform(pca_object.pca_result)\n",
    "\n",
    "#DBscan clustering using PCA reduced features\n",
    "dbscan=DBSCAN(eps=1.5,min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(tsne_result)\n",
    "print(\"dbscan number of clusters\",np.max(dbscan_labels)+1)\n",
    "\n",
    "mask = dbscan_labels != -1\n",
    "filtered_dbscan_labels = dbscan_labels[mask]\n",
    "filtered_true_labels = labels[mask]\n",
    "\n",
    "#confusion matrix\n",
    "conf_matrix = confusion_matrix(filtered_true_labels, filtered_dbscan_labels)\n",
    "#creating a dictionary that maps the \"cluster labels\" number to the most likely correct \"true labels\" number\n",
    "#this time the cluster labels can be more than the true labels, \n",
    "row_ind, col_ind = linear_sum_assignment(-conf_matrix)\n",
    "label_mapping = dict(zip(col_ind, row_ind))\n",
    "mapped_labels = np.zeros_like(filtered_dbscan_labels)\n",
    "for i, j in zip(row_ind, col_ind):\n",
    "    mapped_labels[filtered_dbscan_labels == j] = i\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(filtered_true_labels, mapped_labels)\n",
    "precision = precision_score(filtered_true_labels, mapped_labels, average='macro')\n",
    "recall = recall_score(filtered_true_labels, mapped_labels, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "#find the distances of each point from the first 5 nearest neighbour\n",
    "#this algorithm is done to find the best value for \"eps\" dbscan parameter\n",
    "neighbors = NearestNeighbors(n_neighbors=5)\n",
    "neighbors_fit = neighbors.fit(tsne_result)\n",
    "distances, indices = neighbors_fit.kneighbors(tsne_result)\n",
    "\n",
    "# Sort and plot the distances of each point from the 3rd neighbour\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:, 3]\n",
    "plt.plot(distances)\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Distance to 5th Nearest Neighbor')\n",
    "plt.title('Elbow Method for determining eps')\n",
    "plt.show()\n",
    "\n",
    "#  Visualize the clustering results\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=dbscan_labels, cmap='tab20c',s=9)\n",
    "plt.title('t-SNE Visualization of Clusters')\n",
    "\n",
    "#  Compare with true labels\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='tab20c',s=9)\n",
    "plt.title('t-SNE Visualization with True Labels')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8e143",
   "metadata": {},
   "source": [
    "<h2>autoencoder training for feature extraction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from IPython.display import display\n",
    "\n",
    "paths = path_discovery('images_dataset/')\n",
    "\n",
    "def run_training_subprocess(g1):\n",
    "    \n",
    "    print(\"result will be shown after process finished, check gpu memory usage\\n\")\n",
    "    res = subprocess.run([\"python\", 'train_autoencoder.py']+g1,text=True, capture_output=True)\n",
    "\n",
    "    print(\"return code: \",res.returncode)\n",
    "    print(\"error\",res.stderr)\n",
    "    print(\"output\",res.stdout)\n",
    "\n",
    "    img = Image.open('autoencoder_val_loss.png')\n",
    "    display(img)\n",
    "\n",
    "    \n",
    "encoder_result = run_training_subprocess(paths.img_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fd163",
   "metadata": {},
   "source": [
    "<h2>model autoencoder evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "\n",
    "clear_session()\n",
    "gc.collect()\n",
    "encoder= tf.keras.models.load_model('autoencoder_model')\n",
    "#encoder= ('autoencoder_model')\n",
    "paths = path_discovery('eval_dataset/')\n",
    "\n",
    "def plot_images(original_images, reconstructed_images, n):\n",
    "    \n",
    "    plt.figure(figsize=(5, n * 2))  # Adjust the height based on n for better spacing\n",
    "    for i in range(n):\n",
    "        # Original images\n",
    "        plt.subplot(n, 2, 2 * i + 1)\n",
    "        plt.imshow(original_images[i])\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Reconstructed images\n",
    "        plt.subplot(n, 2, 2 * i + 2)\n",
    "        plt.imshow(reconstructed_images[i])\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "res=input_preprocessing(paths.img_paths)\n",
    "        \n",
    "\n",
    "\n",
    "feature_vector= np.array(res.feature_vector)\n",
    "\n",
    "h1=np.clip(res.original_image, 0, 1)   \n",
    "#plot_images(h1 ,h1, len(h1) ) \n",
    "#feature_vector=feature_vector/255\n",
    "print(f\"Shape of feature_vectors: {feature_vector.shape}\") \n",
    "\n",
    "\n",
    "reconstructed_images=encoder.predict(feature_vector)\n",
    "reconstructed_images = np.clip(reconstructed_images, 0, 1)   \n",
    "reconstructed_images = reconstructed_images.reshape(-1, 224, 224)\n",
    "\n",
    "plot_images(res.original_image ,reconstructed_images, len(res.original_image) ) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
